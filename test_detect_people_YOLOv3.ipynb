{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo():\n",
    "    net = cv2.dnn.readNet(\"yolo/yolov3.weights\", \"yolo/yolov3.cfg\")\n",
    "    classes = []\n",
    "    with open(\"yolo/coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    return net, classes, colors, output_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    # image loading\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
    "    height, width, channels = img.shape\n",
    "    return img, height, width, channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, net, outputLayers):\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(outputLayers)\n",
    "    return blob, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_dimensions(outputs, height, width):\n",
    "    boxes = []\n",
    "    confs = []\n",
    "    class_ids = []\n",
    "    for output in outputs:\n",
    "        for detect in output:\n",
    "            scores = detect[5:]\n",
    "#             print(scores)\n",
    "            class_id = np.argmax(scores)\n",
    "            conf = scores[class_id]\n",
    "            if (conf > 0.3) & (class_id == 0): #keep only people\n",
    "                center_x = int(detect[0] * width)\n",
    "                center_y = int(detect[1] * height)\n",
    "                w = int(detect[2] * width)\n",
    "                h = int(detect[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confs.append(float(conf))\n",
    "                class_ids.append(class_id)\n",
    "#     print(\"Box dimensions obtained\")\n",
    "    return boxes, confs, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(boxes, confs, colors, class_ids, classes, img): \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "#    print(\"Labels drawn\")\n",
    "    cv2.imwrite('results/step.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_detect(img_path):\n",
    "    model, classes, colors, output_layers = load_yolo()\n",
    "    image, height, width, channels = load_image(img_path)\n",
    "    blob, outputs = detect_objects(image, model, output_layers)\n",
    "    boxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "    draw_labels(boxes, confs, colors, class_ids, classes, image)\n",
    "#    print(\"Image detection done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video(video_path):\n",
    "    model, classes, colors, output_layers = load_yolo()\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    # Default resolutions of the frame are obtained.The default resolutions are system dependent.\n",
    "    # We convert the resolutions from float to integer.\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "\n",
    "    # Define the codec and create VideoWriter object.\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'MP4V') \n",
    "    out = cv2.VideoWriter('results/DIOR_test_result_video_yolov3.mp4', fourcc, 25., (frame_width,frame_height))\n",
    "        \n",
    "    i_frame = 0    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        i_frame = i_frame + 1\n",
    "        if i_frame in range(50, 1600, 50):\n",
    "            print(\"Frame {}\".format(i_frame))\n",
    "            \n",
    "        if ret == True:\n",
    "            height, width, channels = frame.shape\n",
    "            blob, outputs = detect_objects(frame, model, output_layers)\n",
    "            boxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "            draw_labels(boxes, confs, colors, class_ids, classes, frame)\n",
    "\n",
    "            cv2.putText(frame, 'TEST RESULT', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "            #cv2.putText(frame, str(i_frame), (150, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
    "\n",
    "            # Write the frame into the file 'output.avi'\n",
    "            out.write(frame)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(\"Video result written\")\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 50\n",
      "Frame 100\n",
      "Frame 150\n",
      "Frame 200\n",
      "Frame 250\n",
      "Frame 300\n",
      "Frame 350\n",
      "Frame 400\n",
      "Frame 450\n",
      "Frame 500\n",
      "Frame 550\n",
      "Frame 600\n",
      "Frame 650\n",
      "Frame 700\n",
      "Frame 750\n",
      "Frame 800\n",
      "Frame 850\n",
      "Frame 900\n",
      "Frame 950\n",
      "Frame 1000\n",
      "Frame 1050\n",
      "Frame 1100\n",
      "Video result written\n"
     ]
    }
   ],
   "source": [
    "video_path = \"video/DIOR_test_video.mp4\"\n",
    "\n",
    "start_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
